{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import optimize\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'X', 'y'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = scipy.io.loadmat('Data/ex4data1.mat')\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['X']\n",
    "y = data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 400)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X = np.concatenate((np.ones([m,1]), X), axis=1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert the vector y into an array\n",
    "# y = np.squeeze(y) \n",
    "y.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = np.where(y == 10, 0, y)\n",
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = len(np.unique(y))\n",
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'Theta1', 'Theta2'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = scipy.io.loadmat('Data/ex4weights.mat')\n",
    "weights.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Theta1 = weights['Theta1']\n",
    "Theta2 = weights['Theta2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientSigmoid(z):\n",
    "    return sigmoid(z)*(1-sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert y array into a matrix Y with dimensions m x K\n",
    "#Y[0,:] = array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=uint8)\n",
    "# Y = np.tile(y, (1,K))\n",
    "# for k in range(K): #0...9\n",
    "#     Y[:,k] = np.where(Y[:,k] == k, 1, 0)\n",
    "# Y.shape\n",
    "\n",
    "#In this exercise it is important the order of Y matrix:\n",
    "#Matlab order, this is 1...10, and not 0...9, then Y[0,:] = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1], dtype=uint8)\n",
    "Y = np.tile(y, (1,K)) #1...10\n",
    "for k in range(1,K+1):\n",
    "    Y[:,k-1] = np.where(Y[:,k-1] == k, 1, 0)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How to multiply element-wise matrices\n",
    "\n",
    "# A = np.ones([3,3])\n",
    "# B = 9*np.ones([3,3])\n",
    "# np.tensordot(A,B)\n",
    "#A.ravel().dot(B.ravel())\n",
    "#np.einsum('ij, ij', A,B) \n",
    "#np.sum(np.multiply(A,B))\n",
    "#sum(sum(A*B)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedforward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X, Theta1, Theta2):\n",
    "    '''\n",
    "    X: matrix of m x n (without the vector of bias X[0,:] != 0)\n",
    "    all the matrix obtained will have dimensions m x something\n",
    "    '''\n",
    "    m = X.shape[0]\n",
    "    a1 = np.concatenate((np.ones([m,1]),X), axis=1)\n",
    "    z2 = a1 @ Theta1.T\n",
    "    a2 = np.concatenate((np.ones([m,1]), sigmoid(z2)), axis=1) \n",
    "    z3 = a2 @ Theta2.T\n",
    "    a3 = np.concatenate((np.ones([m,1]), sigmoid(z3)), axis=1)  #h_Theta\n",
    "    return a1, z2, a2, z3, a3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the difference between logistic regression and neural network is that \n",
    "#in neural networks there is not explicit expression to compute derivative of cost function, \n",
    "#because rule chain, hence it is neccesary to use backpropagation\n",
    "def costFunctionReg(Theta1, Theta2, X, Y, Lambda):\n",
    "    m, K = Y.shape \n",
    "    a1, z2, a2, z3, h_Theta = forward_propagation(X, Theta1, Theta2)\n",
    "    costTerm = -(1/m)*(np.tensordot(Y, np.log(h_Theta[:,1:])) + np.tensordot((np.ones([m,K])-Y), np.log((np.ones([m,K])- h_Theta[:,1:]))))\n",
    "    #costTerm = -(1/m)*(np.einsum('ij, ij',Y, np.log(h_Theta)) + np.einsum('ij, ij', (np.ones([m,K])-Y), np.log((np.ones([m,K])- h_Theta))))\n",
    "    regularizationTerm = (Lambda/(2*m))*((np.linalg.norm(Theta1[:,1:])**2) + (np.linalg.norm(Theta2[:,1:])**2))\n",
    "    J = costTerm + regularizationTerm  \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2876291651613189"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lambda = 0\n",
    "costFunctionReg(Theta1, Theta2, X, Y, Lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38376985909092365"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lambda = 1\n",
    "costFunctionReg(Theta1, Theta2, X, Y, Lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_initialization(s1,s2,s3,epsilon_init):\n",
    "    W1 = np.random.randn(s2, s1 + 1)*2*epsilon_init - epsilon_init\n",
    "    W2 = np.random.randn(s3, s2 + 1)*2*epsilon_init - epsilon_init\n",
    "    return W1, W2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backprogation: Derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A1, Z2, A2, Z3, H_Theta = forward_propagation(X, Theta1, Theta2)\n",
    "gradientSigmoid(Z2[0,:]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation(Theta1, Theta2, X, Y, Lambda):\n",
    "    A1, Z2, A2, Z3, H_Theta = forward_propagation(X, Theta1, Theta2)\n",
    "    \n",
    "    Delta_1 = np.zeros(Theta1.shape) #np.zeros([s2, s1 + 1])\n",
    "    Delta_2 = np.zeros(Theta2.shape) #np.zeros([s3, s2 + 1])\n",
    "    \n",
    "    m  = X.shape[0] #5000\n",
    "   \n",
    "    for t in range(m):\n",
    "        #input of neural network: training example xt\n",
    "        a1 = np.array(A1[t,:]) \n",
    "        \n",
    "        #forward propagation to compute a^(l) with l=2,3\n",
    "        z2 = np.array(Z2[t,:])\n",
    "        a2 = np.array(A2[t,:])\n",
    "        z3 = np.array(Z3[t,:])\n",
    "        a3 = np.array(H_Theta[t,:])\n",
    "\n",
    "        #errors\n",
    "        y_t = np.array(Y[t,:])\n",
    "        delta_3 = a3[1:] - y_t #not include bias unit\n",
    "        delta_2 = np.multiply((Theta2[:,1:].T@delta_3),gradientSigmoid(z2))# ((25 x 10) x 10x1) * 25x1 = 25x1 \n",
    "\n",
    "        #Sum of partials derivatives\n",
    "        Delta_1 += np.outer(delta_2,a1) #25 x 401\n",
    "        Delta_2 += np.outer(delta_3,a2) #10x26\n",
    "        \n",
    "    #Total derivatives \n",
    "    D_1 = Delta_1/m\n",
    "    D_2 = Delta_2/m    \n",
    "    \n",
    "    D_1[:,1:] = D_1[:,1:] + (Lambda/m)*Theta1[:,1:] \n",
    "    D_2[:,1:] = D_2[:,1:] + (Lambda/m)*Theta2[:,1:] \n",
    "    return D_1, D_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.18712766e-05, -2.11248326e-12,  4.38829369e-13, ...,\n",
       "         7.09042553e-09,  1.84706139e-09,  5.60928898e-13],\n",
       "       [ 9.38798109e-05,  1.53233736e-12, -1.95174738e-12, ...,\n",
       "         2.10747891e-08, -8.61281252e-11,  7.08845709e-13],\n",
       "       [-1.92593606e-04, -1.75530893e-12,  1.63207553e-12, ...,\n",
       "         4.63501184e-08,  9.48509834e-10, -1.50133620e-12],\n",
       "       ...,\n",
       "       [ 6.60569302e-05, -1.77854412e-12, -1.96393620e-12, ...,\n",
       "        -9.34100149e-09,  1.29689159e-09,  1.80499812e-12],\n",
       "       [ 2.90522062e-04,  6.10356747e-14,  5.12122016e-13, ...,\n",
       "         3.33797620e-07, -3.66032512e-08,  7.67523996e-13],\n",
       "       [-6.33753316e-05,  1.77175372e-12, -1.31503028e-13, ...,\n",
       "         4.69418663e-09,  2.83929031e-09,  1.75890906e-12]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D1, D2 = backpropagation(Theta1, Theta2, X, Y, 1)\n",
    "D1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeNumericalGradient(Theta1, Theta2, X, Y, Lambda, epsilon):\n",
    "    #Unroll Theta matrix\n",
    "    theta = np.concatenate((np.ravel(Theta1), np.ravel(Theta2)))\n",
    "    N = len(theta)\n",
    "    grad = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        thetaPlus =  np.array(theta) #np.copy(theta) #np.array(theta) #thetaPlus = theta doesn't work\n",
    "        thetaPlus[i] += epsilon\n",
    "        Theta1Plus = thetaPlus[0:Theta1.size].reshape(Theta1.shape)\n",
    "        Theta2Plus = thetaPlus[Theta1.size:].reshape(Theta2.shape)\n",
    "        thetaMinus = np.array(theta) #np.copy(theta) #np.array(theta)\n",
    "        thetaMinus[i] -= epsilon\n",
    "        Theta1Minus = thetaMinus[0:Theta1.size].reshape(Theta1.shape)\n",
    "        Theta2Minus = thetaMinus[Theta1.size:].reshape(Theta2.shape)\n",
    "        J_plus = costFunctionReg(Theta1Plus, Theta2Plus, X, Y, Lambda)\n",
    "        J_minus = costFunctionReg(Theta1Minus, Theta2Minus, X, Y, Lambda)\n",
    "        grad[i] = (J_plus - J_minus)/(2*epsilon)\n",
    "        if i%1000==0:\n",
    "            print(i)\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = Theta1.shape[1] - 1\n",
    "s2 = Theta1.shape[0]\n",
    "s3 = Theta2.shape[0]\n",
    "W1, W2 = random_initialization(s1,s2,s3,epsilon_init=0.12)\n",
    "# appGradient = computeNumericalGradient(Theta1, Theta2, X, Y, Lambda, epsilon=1e-4)\n",
    "# appGradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costFunctionNeuralNetwork(thetaVec, X, Y, Lambda, s2):\n",
    "    #Rolling matrices\n",
    "    s1 = X.shape[1]\n",
    "    s3 = Y.shape[1]\n",
    "    Theta1 = thetaVec[0:(s2*(s1+1))].reshape(s2, s1+1)\n",
    "    Theta2 = thetaVec[(s2*(s1+1)):].reshape(s3, s2+1)\n",
    "    \n",
    "    #J\n",
    "    J = costFunctionReg(Theta1, Theta2, X, Y, Lambda) \n",
    "    \n",
    "    #Gradient vector\n",
    "    D1, D2 = backpropagation(Theta1, Theta2, X, Y, Lambda)\n",
    "    D = np.concatenate((np.ravel(D1), np.ravel(D2)))\n",
    "    return J, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costFunctionWithoutNeuralNetwork(thetaVec, X, Y, Lambda, s2):\n",
    "    #Rolling matrices\n",
    "    s1 = X.shape[1]\n",
    "    s3 = Y.shape[1]\n",
    "    Theta1 = thetaVec[0:(s2*(s1+1))].reshape(s2, s1+1)\n",
    "    Theta2 = thetaVec[(s2*(s1+1)):].reshape(s3, s2+1)\n",
    "    \n",
    "    #J\n",
    "    J = costFunctionReg(Theta1, Theta2, X, Y, Lambda) \n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.920951123041375"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thetaVec = np.concatenate((np.ravel(W1), np.ravel(W2)))\n",
    "s2 = Theta1.shape[0]\n",
    "J, backPropagationGradient = costFunctionNeuralNetwork(thetaVec, X, Y, Lambda, s2)\n",
    "J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.linalg.norm(backPropagationGradient - appGradient)/ np.linalg.norm(backPropagationGradient + appGradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: 0.3351695335126919\n",
       "     jac: array([ 3.15866865e-04, -4.56547343e-07,  3.48834726e-07, ...,\n",
       "       -1.18694711e-04, -7.23641493e-06,  6.55686408e-05])\n",
       " message: 'Maximum number of iterations has been exceeded.'\n",
       "    nfev: 563\n",
       "     nit: 250\n",
       "    njev: 563\n",
       "  status: 1\n",
       " success: False\n",
       "       x: array([-1.26561053e+00, -2.28273672e-03,  1.74417363e-03, ...,\n",
       "        1.44303586e+00, -1.95326953e+00, -3.89015665e-01])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#method = 'CG' #'TNC'\n",
    "res = optimize.minimize(costFunctionNeuralNetwork, x0 = thetaVec, method = 'CG', args=(X,Y, Lambda, s2), jac=True, options = {'maxiter': 250})\n",
    "#res = optimize.minimize(costFunctionWithoutNeuralNetwork, x0 = thetaVec, method = 'CG',  tol=1e-2, args=(X,Y, Lambda, s2), options = {'maxiter': 10, 'disp': True})\n",
    "theta_vec_sol = res.x\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reconstruct solution theta\n",
    "Theta1_solution = theta_vec_sol[0:s2*(s1 + 1)].reshape(s2,s1+1)\n",
    "Theta2_solution = theta_vec_sol[s2*(s1+1):].reshape(s3,s2+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.26561053e+00, -2.28273672e-03,  1.74417363e-03, ...,\n",
       "        -5.09540756e-03,  7.11083621e-03, -1.06362217e-02],\n",
       "       [-1.07497799e+00, -1.15598143e-02, -1.18676632e-03, ...,\n",
       "         9.89491463e-03,  4.00474450e-05, -1.46044816e-02],\n",
       "       [ 1.19123105e-01, -1.23043269e-02, -4.89975685e-03, ...,\n",
       "        -8.84234875e-03, -2.36757997e-03,  6.53237535e-03],\n",
       "       ...,\n",
       "       [-6.12326765e-01, -4.33583987e-03, -1.29866736e-02, ...,\n",
       "         5.11081208e-03,  4.30826049e-03,  2.06971198e-04],\n",
       "       [ 1.04692220e+00, -1.39781392e-03, -7.60998455e-03, ...,\n",
       "         1.31921216e-03, -2.91398552e-02, -7.28542039e-03],\n",
       "       [ 6.52046539e-01, -6.69225720e-03,  1.09826271e-02, ...,\n",
       "        -1.83425509e-02, -4.38360121e-03, -1.60603266e-02]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Theta1_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.25623899e-02, -1.05624163e-08,  2.19414684e-09, ...,\n",
       "        -1.30529929e-05, -5.04175101e-06,  2.80464449e-09],\n",
       "       [-9.83811294e-02,  7.66168682e-09, -9.75873689e-09, ...,\n",
       "        -5.60134007e-05,  2.00940969e-07,  3.54422854e-09],\n",
       "       [ 1.16156052e-01, -8.77654466e-09,  8.16037764e-09, ...,\n",
       "        -1.20951657e-04, -2.33669661e-06, -7.50668099e-09],\n",
       "       ...,\n",
       "       [-1.83220638e-01, -8.89272060e-09, -9.81968100e-09, ...,\n",
       "         2.35311186e-05, -3.25484493e-06,  9.02499060e-09],\n",
       "       [-7.02096331e-01,  3.05178374e-10,  2.56061008e-09, ...,\n",
       "        -8.61759744e-04,  9.43449909e-05,  3.83761998e-09],\n",
       "       [-3.50933229e-01,  8.85876862e-09, -6.57515140e-10, ...,\n",
       "        -1.80365926e-06, -8.14464807e-06,  8.79454531e-09]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Theta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictNeuralNetwork(X,theta1, theta2):\n",
    "    m = X.shape[0]\n",
    "    prediction_digit = np.zeros(m)\n",
    "    probability = np.zeros(m)\n",
    "    a1, z2, a2, z3, a3 = forward_propagation(X, theta1, theta2)\n",
    "    M = np.argmax(a3[:,1:], axis=1) + 1 \n",
    "    prediction_digit = M\n",
    "    #prediction_digit = np.where(M==10,0,M) #because now Y in 1...10\n",
    "    probability = np.max(a3[:,1:], axis=1) #in each row find the maximum\n",
    "    return prediction_digit, probability      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 99.26%\n"
     ]
    }
   ],
   "source": [
    "#predicted, probability = predictNeuralNetwork(X, Theta1, Theta2)\n",
    "predicted, probability = predictNeuralNetwork(X,Theta1_solution, Theta2_solution)\n",
    "correct = np.zeros(m)\n",
    "correct = np.where(np.squeeze(y) == predicted, 1, 0)\n",
    "predicted = np.where(predicted == 10, 0, predicted)\n",
    "print(f'Accuracy = {100*np.mean(correct)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 9, 9, 9], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Prediction of new examples\n",
    "row = np.random.randint(0, m-1)\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        digits = X[row,:].reshape(20,20)\n",
    "        plt.imshow(digits)\n",
    "        plt.axis('off')\n",
    "predicted, probability = predictNeuralNetwork(X[row:row+1,:],Theta1_solution, Theta2_solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The digit is 9\n"
     ]
    }
   ],
   "source": [
    "print(f'The digit is {int(predicted[0])}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
